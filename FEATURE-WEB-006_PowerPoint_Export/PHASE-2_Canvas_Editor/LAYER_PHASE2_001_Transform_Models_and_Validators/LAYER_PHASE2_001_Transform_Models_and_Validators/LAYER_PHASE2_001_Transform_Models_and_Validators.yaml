# ====================================================================================
# LAYER REQUIREMENT TEMPLATE
# ====================================================================================
# This template defines layer-level requirements that implement feature capabilities.
# Layers are the LOWEST level in the requirements hierarchy: Project→System→Feature→Layer
#
# CRITICAL: This file is typically AUTO-GENERATED by build_feature.py --init-layers
# Manual creation should follow the same structure and traceability patterns.
# ====================================================================================
# REQUIREMENTS TRACEABILITY CHAIN:
#   PROJECT Requirements (business goals)
#     ↓ decomposed into
#   SYSTEM Requirements (technical systems)
#     ↓ decomposed into
#   FEATURE Requirements (user-facing features)
#     ↓ decomposed into
#   LAYER Requirements (implementation components) ← YOU ARE HERE
# ====================================================================================
# FOLDER NAMING CONVENTION - CRITICAL FOR PYTHON IMPORTS:
#
# Format: LAYER_{layer_id_underscores}_{layer_name_underscores}
# Example: LAYER_003_001_001_YAML_XML_Reader
#
# Conversion Rules:
#   - Layer ID: LAYER-003-001-001 → LAYER_003_001_001 (hyphens to underscores)
#   - Layer Name: "YAML XML Reader" → YAML_XML_Reader (spaces to underscores)
#
# WHY THIS MATTERS:
#   - Python cannot import modules with spaces or hyphens in names
#   - ModuleNotFoundError if naming doesn't follow convention
#   - build_feature.py enforces this via standardize_layer_folder_name()
#   - No fallback logic exists - violations cause immediate build failures
#
# AUTOMATED CREATION (RECOMMENDED):
#   Command: python build_feature.py --init-layers FEATURE_REQUIREMENTS.yaml
#   Result: Auto-generated folders + YAMLs with correct naming + traceability
#
# MANUAL CREATION (NOT RECOMMENDED):
#   1. Create folder: LAYER_XXX_YYY_ZZZ_LayerName/
#   2. Copy this template to: LAYER_XXX_YYY_ZZZ_LayerName/REQ-XXX-YYY-ZZZ.yaml
#   3. Update ALL [PLACEHOLDER] values
#   4. Ensure metadata.layer_folder EXACTLY matches actual folder name
# ====================================================================================

# ====================================================================================
# METADATA - Identifies this requirement uniquely
# ====================================================================================
metadata:
  requirement_id: "REQ-PHASE2-001"
  requirement_title: "Transform Models and Validators"
  layer_id: "LAYER-PHASE2-001"
  layer_name: "Transform Models and Validators"
  layer_folder: "LAYER_PHASE2_001_Transform_Models_and_Validators"
  
  parent_feature: "FEATURE-WEB-006-PHASE-2_Canvas_Editor_PowerPoint_Slides"
  parent_feature_file: "../FEATURE-WEB-006-PHASE-2.yaml"
  
  version: "1.0.0"
  status: "Active"
  priority: "MUST HAVE"
  created_date: "2025-01-15"
  updated_date: "2025-01-15"
  owner: "Canvas Editor Team"
  target_date: "2025-02-15"
  
  change_log:
    - version: "1.0.0"
      date: "2025-01-15"
      changes: "Initial version - transform models and validators for PowerPoint slide editing"
      author: "AI-derived"

# ====================================================================================
# TRACEABILITY - Shows requirement lineage
# ====================================================================================
traceability:
  parent_feature_requirements:
    - "FEAT-WEB-006-PHASE-2: Canvas Editor for PowerPoint Slide Customization"
    - "MVP-REQ-001: User can resize image by dragging corner handles (maintains aspect ratio)"
    - "MVP-REQ-002: User can drag image to reposition within slide bounds"
    - "MVP-REQ-003: User can crop image by defining crop rectangle"
    - "MVP-REQ-004: Canvas coordinate system must convert to PowerPoint coordinate system accurately"
  
  parent_system_requirements:
    - "SYS-WEB-006: PowerPoint Export with screenshot-based slide generation"
    - "SYS-WEB-API: All endpoints must return FeatureResponse with success/data/error fields"
  
  parent_project_requirements:
    - "PRJ-SYS3: Systems³ Project Reporter - Web dashboard with PowerPoint export"
  
  derivation_rationale: |
    The Canvas Editor requires precise data models for image transformations on PowerPoint slides.
    Users manipulate images in a Fabric.js canvas (pixel coordinates) but final output is PowerPoint
    (EMU coordinates). This layer provides:
    
    1. ImageTransform model: Stores scale (0.5-1.5), position (x,y in pixels), crop bounds
    2. Validation: Ensures scale in range, position within slide bounds, crop non-negative
    3. Coordinate conversion: Canvas pixels → PowerPoint EMUs (914,400 EMUs = 1 inch)
    4. Serialization: Transform data persists across API calls
    
    Without this layer, coordinate conversion would be scattered across multiple files,
    leading to inconsistent calculations and integration bugs.

# ====================================================================================
# REQUIREMENT DEFINITION - What this layer does and why
# ====================================================================================
requirement:
  title: "Image Transform Models and Coordinate Conversion"
  
  description: |
    Provides Pydantic data models for image transformations in the Canvas Editor.
    Handles three transformation types:
    
    1. Scale: Resize image (0.5x to 1.5x, maintains aspect ratio)
    2. Position: Reposition image within 1920x1080 slide bounds
    3. Crop: Define visible region (x, y, width, height in pixels)
    
    Includes critical coordinate conversion between:
    - Canvas coordinates (pixels, origin top-left)
    - PowerPoint coordinates (EMUs, 914,400 per inch)
    
    Validates all transform parameters to prevent invalid states (negative dimensions,
    out-of-bounds positions, invalid scales).
  
  rationale: |
    Canvas Editor users manipulate images in browser using Fabric.js (pixel-based).
    PowerPoint uses EMU (English Metric Units) coordinate system. Without proper
    conversion, images would appear in wrong positions or wrong sizes.
    
    Pydantic models ensure type safety, automatic validation, and clean JSON
    serialization for API responses. Centralizing coordinate conversion in one
    layer prevents calculation errors and ensures consistency.

# ====================================================================================
# SPECIFICATION - Technical details of what to build
# ====================================================================================
specification:
  # File/module structure
  structure:
    entry_point: "src/models.py"
    modules:
      - "models.py"           # Pydantic models for transforms
      - "validators.py"       # Validation functions
      - "converters.py"       # Coordinate conversion utilities
  
  # Main classes to implement
  classes:
    - name: "Position"
      purpose: "Represents x,y position in pixels (canvas coordinates)"
      base_class: "pydantic.BaseModel"
      fields:
        - name: "x"
          type: "float"
          validation: "Must be within slide bounds (0 to 1920)"
          default: "0.0"
        - name: "y"
          type: "float"
          validation: "Must be within slide bounds (0 to 1080)"
          default: "0.0"
      methods:
        - name: "to_ppt_emu"
          signature: "to_ppt_emu(self) -> Tuple[int, int]"
          purpose: "Convert pixel position to PowerPoint EMUs"
          returns: "Tuple of (emu_x, emu_y) where 1 pixel = 9525 EMUs at 96 DPI"
          implementation: |
            # PowerPoint uses EMUs (English Metric Units)
            # 914,400 EMUs = 1 inch
            # At 96 DPI: 914,400 / 96 = 9,525 EMUs per pixel
            emu_x = int(self.x * 9525)
            emu_y = int(self.y * 9525)
            return (emu_x, emu_y)
    
    - name: "CropBounds"
      purpose: "Defines crop rectangle (which part of image is visible)"
      base_class: "pydantic.BaseModel"
      fields:
        - name: "x"
          type: "float"
          validation: "Must be >= 0"
          default: "0.0"
          description: "Left edge of crop rectangle in pixels"
        - name: "y"
          type: "float"
          validation: "Must be >= 0"
          default: "0.0"
          description: "Top edge of crop rectangle in pixels"
        - name: "width"
          type: "float"
          validation: "Must be > 0 and <= original image width"
          default: "1920.0"
          description: "Width of visible area in pixels"
        - name: "height"
          type: "float"
          validation: "Must be > 0 and <= original image height"
          default: "1080.0"
          description: "Height of visible area in pixels"
      methods:
        - name: "validate_bounds"
          signature: "validate_bounds(self, image_width: float, image_height: float) -> bool"
          purpose: "Ensure crop rectangle fits within original image dimensions"
          returns: "True if valid, raises ValueError if invalid"
          implementation: |
            if self.x + self.width > image_width:
                raise ValueError(f"Crop exceeds image width: {self.x + self.width} > {image_width}")
            if self.y + self.height > image_height:
                raise ValueError(f"Crop exceeds image height: {self.y + self.height} > {image_height}")
            return True
    
    - name: "ImageTransform"
      purpose: "Complete transformation data for one slide's image"
      base_class: "pydantic.BaseModel"
      fields:
        - name: "scale"
          type: "float"
          validation: "Must be between 0.5 and 1.5 (50% to 150%)"
          default: "1.0"
          description: "Scale factor (1.0 = original size)"
        - name: "position"
          type: "Position"
          validation: "Validated by Position model"
          default: "Position(x=0, y=0)"
          description: "Top-left corner position on slide"
        - name: "crop"
          type: "Optional[CropBounds]"
          validation: "Validated by CropBounds model if present"
          default: "None"
          description: "Crop bounds (None = no cropping)"
      methods:
        - name: "validate_scale"
          signature: "@validator('scale') def validate_scale(cls, v: float) -> float"
          purpose: "Ensure scale is in valid range"
          returns: "Validated scale value"
          implementation: |
            if v < 0.5 or v > 1.5:
                raise ValueError(f"Scale must be between 0.5 and 1.5, got {v}")
            return v
        
        - name: "to_dict"
          signature: "to_dict(self) -> Dict[str, Any]"
          purpose: "Serialize to dictionary for JSON responses"
          returns: "Dict with scale, position {x, y}, crop {x, y, width, height}"
          implementation: |
            result = {
                "scale": self.scale,
                "position": {"x": self.position.x, "y": self.position.y}
            }
            if self.crop:
                result["crop"] = {
                    "x": self.crop.x,
                    "y": self.crop.y,
                    "width": self.crop.width,
                    "height": self.crop.height
                }
            return result
        
        - name: "calculate_final_dimensions"
          signature: "calculate_final_dimensions(self, original_width: float, original_height: float) -> Tuple[float, float]"
          purpose: "Calculate final image dimensions after scale and crop"
          returns: "Tuple of (final_width, final_height) in pixels"
          implementation: |
            # If cropped, start with crop dimensions
            if self.crop:
                width = self.crop.width
                height = self.crop.height
            else:
                width = original_width
                height = original_height
            
            # Apply scale
            final_width = width * self.scale
            final_height = height * self.scale
            
            return (final_width, final_height)
  
  # Standalone functions
  functions:
    - name: "validate_transform"
      signature: "validate_transform(transform: ImageTransform, slide_width: float = 1920, slide_height: float = 1080) -> Tuple[bool, Optional[str]]"
      purpose: "Validate complete transform fits within slide bounds"
      params:
        - "transform: ImageTransform to validate"
        - "slide_width: Slide width in pixels (default 1920)"
        - "slide_height: Slide height in pixels (default 1080)"
      returns: "Tuple of (is_valid, error_message)"
      implementation: |
        # Check if final positioned image stays within slide bounds
        final_width, final_height = transform.calculate_final_dimensions(1920, 1080)
        
        if transform.position.x + final_width > slide_width:
            return (False, f"Image exceeds slide right edge: {transform.position.x + final_width} > {slide_width}")
        
        if transform.position.y + final_height > slide_height:
            return (False, f"Image exceeds slide bottom edge: {transform.position.y + final_height} > {slide_height}")
        
        return (True, None)
    
    - name: "canvas_to_ppt_dimensions"
      signature: "canvas_to_ppt_dimensions(canvas_width: float, canvas_height: float) -> Tuple[int, int]"
      purpose: "Convert canvas pixel dimensions to PowerPoint EMU dimensions"
      params:
        - "canvas_width: Width in pixels"
        - "canvas_height: Height in pixels"
      returns: "Tuple of (emu_width, emu_height)"
      implementation: |
        # At 96 DPI: 1 pixel = 9,525 EMUs
        EMU_PER_PIXEL = 9525
        emu_width = int(canvas_width * EMU_PER_PIXEL)
        emu_height = int(canvas_height * EMU_PER_PIXEL)
        return (emu_width, emu_height)
  
  # Implementation details
  implementation_details:
    coordinate_system: |
      Canvas (Fabric.js):
      - Origin: Top-left corner (0, 0)
      - Units: Pixels
      - Slide size: 1920x1080 pixels (16:9 ratio)
      
      PowerPoint:
      - Origin: Top-left corner (0, 0)
      - Units: EMUs (English Metric Units)
      - 914,400 EMUs = 1 inch
      - At 96 DPI: 1 pixel = 9,525 EMUs
      - Slide size: 9144000 x 5143500 EMUs (10 inches x 5.625 inches at 96 DPI)
    
    validation_rules: |
      Scale: 0.5 ≤ scale ≤ 1.5
      Position: 0 ≤ x ≤ 1920, 0 ≤ y ≤ 1080
      Crop: x ≥ 0, y ≥ 0, width > 0, height > 0
      Final bounds: position + scaled_dimensions ≤ slide_dimensions
    
    pydantic_usage: |
      All models use Pydantic BaseModel for:
      - Automatic type validation
      - JSON serialization via .dict() or .json()
      - Field validation via @validator decorators
      - Immutability via Config.frozen = True (optional)
  
  # Input/output contract
  inputs:
    - name: "transform_dict"
      type: "Dict[str, Any]"
      description: "Transform data from frontend Fabric.js canvas"
      example: |
        {
          "scale": 0.8,
          "position": {"x": 100, "y": 50},
          "crop": {"x": 0, "y": 0, "width": 1600, "height": 900}
        }
  
  outputs:
    - name: "ImageTransform"
      type: "ImageTransform (Pydantic model)"
      description: "Validated transform object ready for image manipulation"
      example: |
        ImageTransform(
          scale=0.8,
          position=Position(x=100, y=50),
          crop=CropBounds(x=0, y=0, width=1600, height=900)
        )
    
    - name: "FeatureResponse"
      type: "FeatureResponse (dataclass from parent system)"
      description: "API response wrapping transform data"
      example: |
        FeatureResponse(
          success=True,
          data={"transform": transform.to_dict(), "ppt_coords": (952500, 476250)},
          error=None,


# ================================================================================
# ACCEPTANCE CRITERIA - How to verify this layer works correctly
# ================================================================================
acceptance_criteria:
  - criterion: "ImageTransform model correctly validates scale, position, and crop parameters"
    test: "Unit tests verify Pydantic validation catches invalid inputs"
    example: |
      pytest tests/test_models.py::test_validate_scale -v
      pytest tests/test_models.py::test_validate_position_bounds -v
  
  - criterion: "Coordinate conversion from canvas pixels to PowerPoint EMUs is accurate"
    test: "Unit tests verify conversion formula: pixels * 9525 = EMUs"
    example: |
      pytest tests/test_converters.py::test_canvas_to_ppt_conversion -v
  
  - criterion: "Transform serialization to dict produces correct JSON structure"
    test: "Unit tests verify to_dict() output matches expected format"
    example: |
      pytest tests/test_models.py::test_transform_serialization -v
  
  - criterion: "Final dimensions calculation accounts for both crop and scale"
    test: "Unit tests verify calculate_final_dimensions() logic"
    example: |
      pytest tests/test_models.py::test_final_dimensions_with_crop_and_scale -v
  
  - criterion: "Validators reject invalid transform parameters with clear error messages"
    test: "Unit tests for boundary conditions and invalid inputs"
    example: |
      pytest tests/unit/test_transform_validators.py::test_invalid_scale -v
  
  - criterion: "Transform history maintains correct undo/redo state"
    test: "Integration tests for multi-step undo/redo operations"
    example: |
      pytest tests/unit/test_transform_history.py::test_undo_redo_sequence -v
  
  - criterion: "Transform interpolation produces smooth transitions"
    test: "Unit tests verify interpolation factors produce expected results"
    example: |
      pytest tests/unit/test_transform_models.py::test_interpolation -v

# ================================================================================
# TDD IMPLEMENTATION PLAN - Step-by-step guide for implementation
# ================================================================================
week_1_task:
  title: "Build Transform Models and Validators (TDD Approach)"
  
  steps:
    - step: 1
      action: "Write failing unit tests (RED phase)"
      file: "tests/unit/test_transform_models.py"
      tests:
        - "test_transform2d_initialization"
        - "test_transform2d_serialization"
        - "test_transform3d_z_ordering"
        - "test_transform_interpolation"
      duration: "2 hours"
    
    - step: 2
      action: "Run pytest to confirm RED phase"
      command: "pytest tests/unit/test_transform_models.py -v"
      expected: "All tests FAIL (as expected)"
      duration: "2 min"
    
    - step: 3
      action: "Implement Transform2D and Transform3D classes (GREEN phase)"
      file: "src/transform_models/transform_models.py"
      methods:
        - "__init__() → None"
        - "to_dict() → Dict[str, float]"
        - "from_dict(data: Dict) → Transform"
        - "interpolate(target: Transform, factor: float) → Transform"
      duration: "3 hours"
    
    - step: 4
      action: "Run pytest to confirm GREEN phase"
      command: "pytest tests/unit/test_transform_models.py -v"
      expected: "All tests PASS"
      duration: "5 min"
    
    - step: 5
      action: "Refactor for code quality (REFACTOR phase)"
      improvements:
        - "Extract common transform logic to base class"
        - "Add property validation in setters"
        - "Optimize serialization performance"
      duration: "1 hour"
    
    - step: 6
      action: "Integration test with Canvas Editor"
      file: "tests/integration/test_transform_integration.py"
      duration: "1 hour"
  
  total_time: "7 hours 7 minutes"
  
  deliverable: "Fully tested transform models with validation and history tracking"

# ====================================================================================
# INTEGRATION POINTS - How this layer connects to others
# ====================================================================================
integration:
  input_from:
    - layer: "LAYER-WEB-006-001"
      data_type: "Raw transform parameters from UI"
      interface: "HTTP POST /api/slides/{slide_id}/transform"
  
  output_to:
    - layer: "LAYER-PHASE2-002"
      data_type: "Validated Transform objects"
      interface: "TransformManager.apply_transform()"
    - layer: "LAYER-PHASE2-003"
      data_type: "Transform history for undo/redo"
      interface: "TransformHistory.get_history()"
  
  shared_dependencies:
    - "Common type definitions in transform_types.py"
    - "Shared validation rules for UI constraints"

# ================================================================================
# TESTING STRATEGY - Different test levels for this layer
# ================================================================================
testing_strategy:
  unit_tests:
    location: "tests/unit/test_transform_models.py"
    coverage_target: "95%"
    key_scenarios:
      - "Transform initialization with defaults"
      - "Transform serialization/deserialization"
      - "Validation of boundary conditions"
      - "Transform interpolation accuracy"
      - "History tracking operations"
  
  integration_tests:
    location: "tests/integration/test_transform_integration.py"
    scenarios:
      - "Transform pipeline from UI to storage"
      - "Multi-slide batch transformations"
      - "Undo/redo with complex operations"
  
  fixtures:
    location: "tests/fixtures/transforms/"
    files:
      - "valid_transforms.json"
      - "invalid_transforms.json"
      - "edge_case_transforms.json"

# ================================================================================
# DEPLOYMENT NOTES - How to deploy/use this layer
# ================================================================================
deployment:
  dependencies:
    - package: "pydantic"
      version: ">=2.0.0"
      purpose: "Data validation and serialization"
    - package: "numpy"
      version: ">=1.20.0"
      purpose: "Mathematical operations for transforms"
  
  configuration:
    - setting: "TRANSFORM_HISTORY_SIZE"
      value: "50"
      location: "config/transform_settings.yaml"
    - setting: "TRANSFORM_BOUNDS"
      value: "{'min_x': -5000, 'max_x': 5000, 'min_y': -5000, 'max_y': 5000}"
      location: "config/transform_settings.yaml"
  
  usage_example: |
    # Example of how to use this layer
    from src.transform_models import Transform2D, TransformValidator, TransformHistory
    
    # Create and validate a transform
    validator = TransformValidator()
    transform = Transform2D(x=100, y=200, width=300, height=200)
    
    is_valid, error = validator.validate_transform(transform)
    if is_valid:
        # Record for history
        history = TransformHistory()
        history.record_transform("slide_001", transform)
        
        # Apply interpolation
        target = Transform2D(x=200, y=300, width=400, height=300)
        interpolated = transform.interpolate(target, 0.5)

# ================================================================================
# CODE GENERATION CONSTRAINTS - CRITICAL for AI Code Generation Quality
# ================================================================================
# These constraints MUST be followed when AI generates implementation code
# Violations will cause runtime errors and integration failures
# ================================================================================
code_generation_constraints:
  
  # Output Format Rules - Prevents markdown wrapping
  output_format:
    - "Return ONLY raw Python code - NO explanations or commentary"
    - "NO markdown code fences (```python or ```)"
    - "First line MUST be valid Python (import statement, class definition, or function)"
    - "Last line MUST be valid Python code (NOT a closing markdown fence)"
    - "File must be directly executable without any preprocessing"
  
  # API Usage Rules - Prevents method invention
  api_usage:
    - "ONLY call methods that are explicitly defined in this layer's interface"
    - "DO NOT invent method variations, aliases, or similar names"
    - "Use EXACT method names as specified in requirements"
    - "If a method is not listed in the interface, DO NOT create or call it"
    - "Method signatures must match exactly (parameter names, types, return types)"
  
  # Import Completeness Rules - Prevents missing imports
  import_completeness:
    - "Import ALL types used in type hints (Dict, List, Optional, Tuple, Any, Union, etc.)"
    - "Import ALL third-party libraries before use"
    - "Import ALL standard library modules before use"
    - "Verify all imported names are actually used in the code"
    - "Remove unused imports to maintain clean code"
  
  # Naming Convention Rules - Ensures consistency
  naming_conventions:
    - "Primary class name MUST match the layer name or be clearly related"
    - "Use descriptive, unambiguous names for methods and variables"
    - "Follow PEP 8 naming conventions (snake_case for functions, PascalCase for classes)"
    - "Avoid generic names like 'process', 'handle', 'do' without context"
  
  # Code Quality Rules - Prevents stub/placeholder code
  quality_requirements:
    - "NO stub implementations (pass statements without logic)"
    - "NO placeholder comments like TODO, FIXME, NOT IMPLEMENTED"
    - "NO fake/mock data unless explicitly required for testing"
    - "ALL methods must have complete, working implementations"
    - "Code must be production-ready, not a prototype"
  
  # Validation Requirements - Ensures code correctness
  validation_requirements:
    - "Code MUST be syntactically valid Python 3.10+"
    - "All referenced attributes MUST exist on their objects"
    - "All method calls MUST match actual method signatures"
    - "Type hints must be accurate and complete"
    - "Code must pass basic static analysis (no obvious errors)"

# ================================================================================
# NOTES - Additional context, gotchas, or important information
# ================================================================================
notes: |
  IMPORTANT CONSIDERATIONS:
  - Transform coordinates are relative to canvas origin (top-left)
  - Rotation is stored in degrees but may need radians for rendering
  - Z-ordering in Transform3D affects render order but not collision detection
  - History size is limited to prevent memory bloat in long editing sessions
  
  DESIGN DECISIONS:
  - Chose separate 2D/3D models over unified model for performance
  - Validation is separate from models to support different validation rules
  - History uses command pattern for clean undo/redo implementation
  
  FUTURE ENHANCEMENTS:
  - Add transform constraints (e.g., maintain aspect ratio)
  - Support transform groups for multi-slide operations
  - Add transform animation curve support

# ================================================================================
# END OF LAYER REQUIREMENT
# ================================================================================